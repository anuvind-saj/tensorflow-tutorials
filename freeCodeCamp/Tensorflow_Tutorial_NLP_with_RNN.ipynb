{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Tutorial_NLP with RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmSKs1ULFbjpJxMYMTLEST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuvind-saj/tensorflow-tutorials/blob/AI_ML/freeCodeCamp/Tensorflow_Tutorial_NLP_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdRR_pSV7HWV",
        "outputId": "a4c3bfab-be44-4fe1-dcea-10bab7f56235"
      },
      "source": [
        "vocab = {}  # maps word to integer representing it\n",
        "word_encoding = 1\n",
        "def bag_of_words(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
        "  bag = {}  # stores all of the encodings and their frequency\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      encoding = vocab[word]  # get encoding from vocab\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding = word_encoding\n",
        "      word_encoding += 1\n",
        "    \n",
        "    if encoding in bag:\n",
        "      bag[encoding] += 1\n",
        "    else:\n",
        "      bag[encoding] = 1\n",
        "  \n",
        "  return bag\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "bag = bag_of_words(text)\n",
        "print(bag)\n",
        "print(vocab)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeIgUZZMBwo7",
        "outputId": "e8116b20-e09c-4b2e-c0d4-8500a4298d21"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_bag)\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z30C3SGB75a",
        "outputId": "337137f8-f280-433e-de48-fc706efe7d6e"
      },
      "source": [
        "print(word_encoding)\n",
        "print(vocab)\n",
        "print(bag)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9, 'i': 10, 'thought': 11, 'the': 12, 'movie': 13, 'was': 14, 'going': 15, 'be': 16, 'bad': 17, 'but': 18, 'it': 19, 'actually': 20, 'amazing': 21}\n",
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gW-_AFgcZXJ",
        "outputId": "8d736641-7ec5-4c62-ab38-f02ae044f44c"
      },
      "source": [
        "vocab = {}  \n",
        "word_encoding = 1\n",
        "def one_hot_encoding(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \") \n",
        "  encoding = []  \n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      code = vocab[word]  \n",
        "      encoding.append(code) \n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding.append(word_encoding)\n",
        "      word_encoding += 1\n",
        "  \n",
        "  return encoding\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "encoding = one_hot_encoding(text)\n",
        "print(encoding)\n",
        "print(vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_alLHGDRcsi7",
        "outputId": "f63a8508-09b9-42e9-f14c-fd4b24e0f5b4"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_bag)\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLxN07hVdADG",
        "outputId": "6129ba7a-adbb-41a9-993c-791f5bccf54d"
      },
      "source": [
        "# Sentiment Analysis on Movie Reviews using RNN\n",
        "\n",
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQbwY2YldSpj"
      },
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxm-FaCkifVN",
        "outputId": "e00f32c7-2526-44d5-d4b1-4d796c049eb9"
      },
      "source": [
        "train_data[34]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17319, 15727,   382,     4,   833,  5102,     7,    22,   228,\n",
              "           7,    32,    58,    27,  1956,  1053,    23,   998, 14261,\n",
              "         967, 24640,   315,     4,  2226,     5,  2084,     4,    85,\n",
              "           9,     4,   480,  5633,  1381,     7,  2901,  2567,    63,\n",
              "         166,     4,    22,  4152,  5754,     8,     4,   744,    11,\n",
              "         175,    85,  2550, 11176,   475,   455,  4127,     9,     6,\n",
              "        5360,    22,    15,   127,   164,     8,  6802,     4,  2577,\n",
              "           7,    94,  1020,   177,     5,  1051,  2173,   739,   576,\n",
              "        1815,   469,     4,    22,    27,  1153, 50141,   328,  2666,\n",
              "         187,    27,   523,     5,  2391, 16881,  6521,    27,   239,\n",
              "        1503,     4,   644, 14498, 18869,  3372,     6,   176,     7,\n",
              "        1279,  6840,    21,   996,     8,  2522,    19,    41,   196,\n",
              "       10168,     5,  1815,  6524,  8920,    44,     4,   771,     7,\n",
              "       15565,     4,   360,     7,     4,   156,    26,  1053,    11,\n",
              "        1420,     5,  9364,   555,     4,    91,   906,     7,    63,\n",
              "        1085,  3281,  3544,   397,    41,  3967,  5706,   125,    34,\n",
              "           4,  9539,  4127,     4,   114,     9,   964,  1835,    39,\n",
              "         380,     8,  1363,    19,   141,  5400,   844,    17,     4,\n",
              "        4127,  4042,  1861,     6,   968,    11,     4,  5244,  2059,\n",
              "          15, 27746,     5,  6082,     4,   719, 55676,   261,    45,\n",
              "        3084,     8,  1408,    15, 15565,    26,  1089,  2373,    19,\n",
              "        2038,  1438,     4,   326,    15,     6,  4127,   100,   114,\n",
              "        1060,   429,     6,   686,   406, 14262,     5,  1671,    12,\n",
              "          46,    38, 69999,     9,  1254,  1755, 11176,   475,   455,\n",
              "        4127,     9,    66,    31,    18, 14584,     7,     4,   132,\n",
              "        1918,  2773,  7179,    39,     4,   522,  2226,    91,    80,\n",
              "         216,   245,    39,     4,    22,  5870,    68,  1828,    11,\n",
              "        2793,     5, 13914,    68,  2698,    19,  4853], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tx72fe8ja0Y"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PLYdOK-mQwC",
        "outputId": "001a6fb9-49aa-4650-d104-4e2cb792f0d4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeA7wTpAmvbx",
        "outputId": "872b121e-8773-443c-cd05-7dfac47bf812"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 21s 21ms/step - loss: 0.4270 - acc: 0.8048 - val_loss: 0.3027 - val_acc: 0.8792\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 12s 20ms/step - loss: 0.2347 - acc: 0.9128 - val_loss: 0.3238 - val_acc: 0.8766\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 12s 20ms/step - loss: 0.1850 - acc: 0.9317 - val_loss: 0.2625 - val_acc: 0.8902\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 12s 20ms/step - loss: 0.1523 - acc: 0.9477 - val_loss: 0.4319 - val_acc: 0.8772\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.1294 - acc: 0.9538 - val_loss: 0.2920 - val_acc: 0.8882\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.1141 - acc: 0.9609 - val_loss: 0.3164 - val_acc: 0.8870\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0984 - acc: 0.9665 - val_loss: 0.3135 - val_acc: 0.8890\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0871 - acc: 0.9707 - val_loss: 0.3128 - val_acc: 0.8860\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 13s 22ms/step - loss: 0.0777 - acc: 0.9747 - val_loss: 0.4736 - val_acc: 0.8764\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.0684 - acc: 0.9780 - val_loss: 0.3949 - val_acc: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JITh2J0owQ8",
        "outputId": "3c2c225c-180c-4cba-b33f-014b66748bf0"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4862 - acc: 0.8559\n",
            "[0.48618805408477783, 0.8559200167655945]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m0Hyr5Xo3UX",
        "outputId": "ebb4d211-ba73-47c7-ec30-897b9f008882"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NvXpbPWo4FY",
        "outputId": "41af95f6-f1c6-49a2-904f-b3d2edba1a83"
      },
      "source": [
        "# while were at it lets make a decode function\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "  \n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was just amazing so amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDyLDxk2pyxq",
        "outputId": "53df6ce6-2717-48c1-8a30-90a96e66f423"
      },
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred) \n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was a fantastic! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"That movie really bad. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.97789454]\n",
            "[0.36471048]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}